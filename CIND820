#Splitting data into train and test
#We split this data into 75% and 25% for train and test sets respectively 
#using sklearn.model_selection train_test_split.
#we transform the data.
#we use x_train and x_test to transform them into xtrain_scaler 
#and xtest_scalar because there are many observations with large ranges 
#such as ‘TOTAL_PAY’, ‘LIMIT_BALANCE’ and ‘TOTAL_BILL’.
#We are using MinMaxScaler to scale our variables and convert them in 
#the range 0-1.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
x = data[['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_1', 'PAY_2',
       'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',
       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',
       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]
y = data['def_pay']

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=3)

xtrain_scaler = MinMaxScaler().fit_transform(x_train)
xtest_scaler = MinMaxScaler().fit_transform(x_test)





#Logistic model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV

c_val = [0.001,0.01,0.1,0.5,1.0]

logreg = LogisticRegression(solver = 'liblinear')
hyperParam = [{'C':c_val}]

gsv = GridSearchCV(logreg,hyperParam,cv=5,verbose=1)
#Fitting model with x_train and y_train
best_model = gsv.fit(x_train, y_train)

print("Best Accuracy :",best_model.score(x_test, y_test))   

#Transformed training and testing data
c_val = [0.001,0.01,0.1,0.5,1.0]

logreg = LogisticRegression(solver = 'liblinear')
hyperParam = [{'C':c_val}]

gsv = GridSearchCV(logreg,hyperParam,cv=5,verbose=1)
best_model = gsv.fit(xtrain_scaler, y_train)
#Predicting the results
logreg_pred_mms = best_model.best_estimator_.predict(xtest_scaler)

print("Best Accuracy :",best_model.score(xtest_scaler, y_test))

#Confusion Matrix of model with transformed data
from sklearn.metrics import plot_confusion_matrix
from sklearn import metrics
plot_confusion_matrix(gsv,xtest_scaler, y_test)

conf_metr = confusion_matrix(y_test, logreg_pred_mms)

print("Confusion Matrix: \n {}".format(conf_metr))
print(metrics.classification_report(y_test,logreg_pred_mms))
print("Accuracy:",metrics.accuracy_score(y_test, logreg_pred_mms))
print("Recall/Sensitivity/True Positive Rate:",metrics.recall_score(y_test, logreg_pred_mms))
print("Precision:",metrics.precision_score(y_test, logreg_pred_mms))

#ROC Curve:
metrics.plot_roc_curve(gsv, xtest_scaler, y_test)





#Decision Tree
from sklearn.tree import DecisionTreeClassifier
import numpy as np

i = 1
d = np.arange(1, 20, 1)
depth = []
for i in d:
    dtree = DecisionTreeClassifier(max_depth=i)
    # Fitting model with x_train and y_train
    dtree.fit(x_train, y_train)
    # Predicting the results
    dtree_pred = dtree.predict(x_test)
    depth.append(metrics.accuracy_score(y_test, dtree_pred))

m = max(depth)

print("We got max accuracy of {0} when max_depth = {1}". format(max(depth), [i+1 for i, j in enumerate(depth) if j == m]))

#Transformed training and testing data
i = 1
d = np.arange(1, 20, 1)
depth_mms = []
for i in d:
    dtree = DecisionTreeClassifier(max_depth=i)
    dtree.fit(xtrain_scaler, y_train)
    dtree_pred_mms = dtree.predict(xtest_scaler)
    depth_mms.append(metrics.accuracy_score(y_test, dtree_pred_mms))

m = max(depth_mms)

print("We got max accuracy of {0} when max_depth = {1}". format(max(depth_mms), [i+1 for i, j in enumerate(depth_mms) if j == m]))

#Confusion Matrix of model with transformed data
plot_confusion_matrix(dtree, xtest_scaler, y_test)

conf_metr = metrics.confusion_matrix(y_test, dtree_pred_mms)

print("Confusion Matrix: \n {}".format(conf_metr))
print(metrics.classification_report(y_test,dtree_pred_mms))
print("Accuracy:",metrics.accuracy_score(y_test, dtree_pred_mms))
print("Recall/Sensitivity/True Positive Rate:",metrics.recall_score(y_test, dtree_pred_mms))
print("Precision:",metrics.precision_score(y_test, dtree_pred_mms))

#ROC Curve:
metrics.plot_roc_curve(dtree, xtest_scaler, y_test)




#Random Forest
from sklearn.ensemble import RandomForestClassifier
#with transformed data
estimators = [10,50,80,100,150,200,250,300]

rf = RandomForestClassifier(max_depth=3,random_state=5)
hyperParam = [{'n_estimators':estimators}]

gsv = GridSearchCV(rf,hyperParam,cv=5,verbose=1)
best_model = gsv.fit(xtrain_scaler, y_train)
rf_pred_mms = best_model.best_estimator_.predict(xtest_scaler)

print("Best Accuracy :",best_model.score(xtest_scaler, y_test))

#Confusion Matrix of model with transformed data
plot_confusion_matrix(gsv, xtest_scaler, y_test)

conf_metr = confusion_matrix(y_test, rf_pred_mms)

print("Confusion Matrix: \n {}".format(conf_metr))
print(metrics.classification_report(y_test,rf_pred_mms))
print("Accuracy:",metrics.accuracy_score(y_test, rf_pred_mms))
print("Recall/Sensitivity/True Positive Rate:",metrics.recall_score(y_test, rf_pred_mms))
print("Precision:",metrics.precision_score(y_test, rf_pred_mms))

#ROC Curve:
metrics.plot_roc_curve(gsv, xtest_scaler, y_test)




#KNN
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix, confusion_matrix
#Using normal train and test data
i = 1
k = np.arange(1, 30, 1)
k_val_acc = []
for i in k:
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(x_train, y_train)
    y_pred = knn.predict(x_test)
    k_val_acc.append(metrics.accuracy_score(y_test, y_pred))
    
m = max(k_val_acc)

print("We got max accuracy of {0} when K = {1}". format(max(k_val_acc), [i+1 for i, j in enumerate(k_val_acc) if j == m]))

#Using transformed train and test data
i = 1
k = np.arange(1, 30, 1)
k_val_acc_mms = []
for i in k:
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(xtrain_scaler, y_train)
    y_pred_mms = knn.predict(xtest_scaler)
    k_val_acc_mms.append(metrics.accuracy_score(y_test, y_pred_mms))
    
m = max(k_val_acc_mms)

print("We got max accuracy of {0} when K = {1}". format(max(k_val_acc_mms), [i+1 for i, j in enumerate(k_val_acc_mms) if j == m]))

#Confusion Matrix of model with transformed data
plot_confusion_matrix(knn, xtest_scaler, y_test)

conf_metr = metrics.confusion_matrix(y_test, y_pred_mms)

print("Confusion Matrix: \n {}".format(conf_metr))
print(metrics.classification_report(y_test,y_pred_mms))
print("Accuracy:",metrics.accuracy_score(y_test, y_pred_mms))
print("Recall/Sensitivity/True Positive Rate:",metrics.recall_score(y_test, y_pred_mms))
print("Precision:",metrics.precision_score(y_test, y_pred_mms))

#ROC Curve:
metrics.plot_roc_curve(knn, xtest_scaler, y_test)




#Support Vector Classifier
from sklearn.svm import SVC

#Using transformed train and test data
kernels = ['rbf','linear','poly','sigmoid']

svc = SVC()
hyperParam = [{'kernel':kernels}]

gsv = GridSearchCV(svc,hyperParam,cv=5,verbose=1)
best_model = gsv.fit(xtrain_scaler, y_train)
svc_pred_mms = best_model.best_estimator_.predict(xtest_scaler)

print("Best Accuracy :",best_model.score(xtest_scaler, y_test))

#Confusion Matrix of model with transformed data
plot_confusion_matrix(gsv, xtest_scaler, y_test)

conf_metr = confusion_matrix(y_test, svc_pred_mms)

print("Confusion Matrix: \n {}".format(conf_metr))
print(metrics.classification_report(y_test,svc_pred_mms))
print("Accuracy:",metrics.accuracy_score(y_test, svc_pred_mms))
print("Recall/Sensitivity/True Positive Rate:",metrics.recall_score(y_test, svc_pred_mms))
print("Precision:",metrics.precision_score(y_test, svc_pred_mms))

#ROC Curve:
metrics.plot_roc_curve(gsv, xtest_scaler, y_test)




#Bagging with all classifiers using Cross Validation
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import BaggingClassifier

#Creating classifiers
knn = KNeighborsClassifier()
lg = LogisticRegression()
dt = DecisionTreeClassifier()
rf = RandomForestClassifier()
svc = SVC()

clf_array = [knn, lg, dt, rf,svc]

for clf in clf_array:
    cc_scores = cross_val_score(clf, x, y, cv=10, n_jobs=-1)
    bagging_clf = BaggingClassifier(clf, max_samples=0.25, max_features=10, random_state=3)
    bagging_scores = cross_val_score(bagging_clf, x, y, cv=10, n_jobs=-1)
    
    print("Accuracy of: {1:.3f}, std: (+/-) {2:.3f} [{0}]".format(clf.__class__.__name__,cc_scores.mean(), cc_scores.std()))
    print("Accuracy of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\n".format(clf.__class__.__name__,bagging_scores.mean(), bagging_scores.std()))





#Boosting with all classifiers using Cross Validation
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from mlxtend.classifier import EnsembleVoteClassifier

#Creating classifiers
knn = KNeighborsClassifier()
lg = LogisticRegression()
dt = DecisionTreeClassifier()
rf = RandomForestClassifier()
svc = SVC()
ada_boost = AdaBoostClassifier()
grad_boost = GradientBoostingClassifier()
xgb_boost = XGBClassifier()
boost_array = [ada_boost, grad_boost, xgb_boost]
clf = [knn, lg, dt, rf,svc]
eclf = EnsembleVoteClassifier(clfs=[ada_boost, grad_boost, xgb_boost], voting='hard')
labels = ['Ada Boost', 'Grad Boost', 'XG Boost', 'Ensemble']
for clf, label in zip([ada_boost, grad_boost, xgb_boost, eclf], labels):
    scores = cross_val_score(clf, x, y, cv=10, scoring='accuracy')
    print("Accuracy: {0:.3f}, std: (+/-) {1:.3f} [{2}]".format(scores.mean(), scores.std(), label))
